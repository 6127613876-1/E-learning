[
    {
        "video_id": "ukzFI9rgwfU",
        "title": "Machine Learning | What Is Machine Learning? | Introduction To Machine Learning | 2024 | Simplilearn",
        "url": "https://www.youtube.com/watch?v=ukzFI9rgwfU",
        "duration": 472,
        "transcript": "we know humans learn from their past experiences and machines follow instructions given by humans but what if humans can train the machines to learn from the past data and do what humans can do and much faster well that's called machine learning but it's a lot more than just learning it's also about understanding and reasoning so today we will learn about the basics of machine learning so that's paul he loves listening to new songs he either likes them or dislikes them paul decides this on the basis of the song's tempo genre intensity and the gender of voice for simplicity let's just use tempo and intensity for now so here tempo is on the x axis ranging from relaxed to fast whereas intensity is on the y axis ranging from light to soaring we see that paul likes the song with fast tempo and soaring intensity while he dislikes the song with relaxed tempo and light intensity so now we know paul's choices let's say paul listens to a new song let's name it as song a song a has fast tempo and a soaring intensity so it lies somewhere here looking at the data can you guess whether paul will like the song or not correct so paul likes this song by looking at paul's past choices we were able to classify the unknown song very easily right let's say now paul listens to a new song let's label it as song b so song b lies somewhere here with medium tempo and medium intensity neither relaxed nor fast neither light nor soaring now can you guess whether paul likes it or not not able to guess whether paul will like it or dislike it are the choices unclear correct we could easily classify song a but when the choice became complicated as in the case of song b yes and that's where machine learning comes in let's see how in the same example for song b if we draw a circle around the song b we see that there are four votes for like whereas one would for dislike if we go for the majority votes we can say that paul will definitely like the song that's all this was a basic machine learning algorithm also it's called k nearest neighbors so this is just a small example in one of the many machine learning algorithms quite easy right believe me it is but what happens when the choices become complicated as in the case of song b that's when machine learning comes in it learns the data builds the prediction model and when the new data point comes in it can easily predict for it more the data better the model higher will be the accuracy there are many ways in which the machine learns it could be either supervised learning unsupervised learning or reinforcement learning let's first quickly understand supervised learning suppose your friend gives you one million coins of three different currencies say one rupee one euro and one dirham each coin has different weights for example a coin of one rupee weighs three grams one euro weighs seven grams and one dirham weighs four grams your model will predict the currency of the coin here your weight becomes the feature of coins while currency becomes the label when you feed this data to the machine learning model it learns which feature is associated with which label for example it will learn that if a coin is of 3 grams it will be a 1 rupee coin let's give a new coin to the machine on the basis of the weight of the new coin your model will predict the currency hence supervised learning uses labeled data to train the model here the machine knew the features of the object and also the labels associated with those features on this note let's move to unsupervised learning and see the difference suppose you have cricket data set of various players with their respective scores and wickets taken when you feed this data set to the machine the machine identifies the pattern of player performance so it plots this data with the respective wickets on the x-axis while runs on the y-axis while looking at the data you'll clearly see that there are two clusters the one cluster are the players who scored higher runs and took less wickets while the other cluster is of the players who scored less runs but took many wickets so here we interpret these two clusters as batsmen and bowlers the important point to note here is that there were no labels of batsmen and bowlers hence the learning with unlabeled data is unsupervised learning so we saw supervised learning where the data was labeled and the unsupervised learning where the data was unlabeled and then there is reinforcement learning which is a reward based learning or we can say that it works on the principle of feedback here let's say you provide the system with an image of a dog and ask it to identify it the system identifies it as a cat so you give a negative feedback to the machine saying that it's a dog's image the machine will learn from the feedback and finally if it comes across any other image of a dog it will be able to classify it correctly that is reinforcement learning to generalize machine learning model let's see a flowchart input is given to a machine learning model which then gives the output according to the algorithm applied if it's right we take the output as a final result else we provide feedback to the training model and ask it to predict until it learns i hope you've understood supervised and unsupervised learning so let's have a quick quiz you have to determine whether the given scenarios uses supervised or unsupervised learning simple right scenario one facebook recognizes your friend in a picture from an album of tagged photographs scenario 2 netflix recommends new movies based on someone's past movie choices scenario 3 analyzing bank data for suspicious transactions and flagging the fraud transactions think wisely and comment below your answers moving on don't you sometimes wonder how is machine learning possible in today's era well that's because today we have humongous data available everybody is online either making a transaction or just surfing the internet and that's generating a huge amount of data every minute and that data my friend is the key to analysis also the memory handling capabilities of computers have largely increased which helps them to process such huge amount of data at hand without any delay and yes computers now have great computational powers so there are a lot of applications of machine learning out there to name a few machine learning is used in healthcare where diagnostics are predicted for doctor's review the sentiment analysis that the tech giants are doing on social media is another interesting application of machine learning fraud detection in the finance sector and also to predict customer churn in the e-commerce sector while booking a gap you must have encountered surge pricing often where it says the fair of your trip has been updated continue booking yes please i'm getting late for office well that's an interesting machine learning model which is used by global taxi giant uber and others where they have differential pricing in real time based on demand the number of cars available bad weather rush r etc so they use the surge pricing model to ensure that those who need a cab can get one also it uses predictive modeling to predict where the demand will be high with the goal that drivers can take care of the demand and search pricing can be minimized great hey siri can you remind me to book a cab at 6 pm today ok i'll remind you thanks no problem comment below some interesting everyday examples around you where machines are learning and doing amazing jobs so that's all for machine learning basics today from my site keep watching this space for more interesting videos until then happy learning"
    },
    {
        "video_id": "KNAWp2S3w94",
        "title": "Intro to Machine Learning (ML Zero to Hero - Part 1)",
        "url": "https://www.youtube.com/watch?v=KNAWp2S3w94",
        "duration": 438,
        "transcript": "♪ (music) ♪ You've probably heard a lot\nabout AI machine learning over the last few months. And maybe you've been inspired\nby videos showing what's possible with AI machine learning. But what is it really? Once you go beyond the hype\nand get down to writing code, what does AI really look like? Well, that's what we're going\nto go through in this video series, where we'll teach you what it's like\nto write code for machine learning, and how it provides different,\nnew, and exciting scenarios that will help you write applications that behave more like a human being,\ngiving you artificial intelligence. I'm Laurence,\nand I'm going to be your guide. You don't need\nto know a lot to get started, and we'll be using the Python language. Don't worry if you've never used it,\nit's super simple to understand, and you'll be up and running in no time. So let's start with a very simple example. Consider you're creating a game\nof Rock, Paper, Scissors. When you play this\nwith a human, it's very basic; every child can learn it\nin just a few minutes. Now, let's take a look\nat the most basic part of a game that the human brain is really good at, and that's recognizing\nwhat it's actually looking at. So consider these images. Most people can look at them\nand instantly recognize which ones are rock, which ones are paper, and which ones are scissors. But how would you program\na computer to recognize them? Think about all of the diversity\nof hand types, skin color, and even people who do scissors\nlike me, with their thumb sticking out, and people who do scissors\nwith their thumb in. If you've ever written any kind of code,\nyou'll instantly realize that this is a really,\nreally difficult task. It might take you thousands\nor tens of thousands of lines of code, and that's just to play\nrock, paper, or scissors. So what if there was\na different way to teach a computer to recognize what it sees? What if you could have\na computer learn in the same way that a human does? That's the core of machine learning\nand the path to artificial intelligence. So traditional programming\nlooks like this. You have data, for example,\na feed from the webcam, and you have rules that act on this data. These rules are expressed\nin a programming language and are the bulk\nof any code that you write. Ultimately, these rules will act\non the data and give you an answer. Maybe it sees a rock,\nmaybe it sees a paper, and maybe it sees scissors. But what if you turn this diagram around, and instead of you as the programmer\nfiguring out the rules, you instead give\nit answers with the data and have the computer\nfigure out what the rules are. That's machine learning. So now, I can have\nlots of pictures of rocks and tell a computer\nthat this is what a rock looks like, and this is what paper looks like, and this is what scissors looks like. And I can have a computer\nfigure out the patterns that match them to each other. Then, my computer will have learned\nto recognize a rock, paper, and scissors. That's the core of building something\nthat uses machine learning. You get a set of data\nthat has patterns inherent in it, and you have a computer learn\nwhat those patterns are. Before we write a neural network that learns something as complex\nas rock, paper, and scissors, let's use a much simpler example. Take a look at these numbers-- there's a relationship\nbetween the X and Y values. Can you see it? It's actually Y = 2X - 1. So if you saw it, how did you get that? Maybe you noticed\nthat the Y value increases by 2, while the X value only increases by 1. So it was Y = 2X \nplus a minus something. And then, you may have seen\nthat when X was zero, Y was minus one, so you figured Y = 2X - 1\nwould be a good guess, and then you took a look\nat the other numbers and saw that it worked. That's exactly the principle\nthat all machine learning works on. So let's take a look. This is the entire code that you can use\nto create a machine-learned model that figures out what matches\nthese numbers to each other. Don't worry if some of it\ndoesn't look very familiar right now, you'll be able to pick that up in no time. This first line defines the model itself. A model is a trained neural network, and here we have\nthe simplest possible neural network, which, in this case, is a single layer\nindicated by the keras.layers.Dense code. And that layer has a single neuron in it,\nindicated by units = 1. We also feed a single value\ninto the neural network, which is the X value, and we'll have the neural network\npredict what the Y would be for that X. So that's why we just say\nthat input_shape is one value. When you compile the model, \nthere are two functions: the loss and the optimizer. These are the key to machine learning. How machine learning works\nis that the model will make a guess about the relationship\nbetween the numbers. For example, it might guess\nthat Y = 5X + 5. And when training, it will then calculate how good or how bad that guess is,\nusing the loss function. And then, it will use\nthe optimizer function to generate another guess. The logic is that the combination\nof these two functions will slowly get us closer and closer\nto the correct formula. And, in this case, it will go through\nthat loop 500 times, making a guess, calculating\nhow accurate that guess is, and then using the optimizer\nto enhance that guess, and so on. The data itself is set up\nas an array of Xs and Ys, and our process\nof matching them to each other is in the fit method of the model. We literally say, \"fit the Xs\nto the Ys and try this 500 times.\" When it's done,\nwe'll have a trained model. So now you can try to predict\na Y value for a given X. What do you think would happen\nif you tried this line of code predict the Y when X equals 10? You might think\nthat the answer is 19, right? But it isn't. It's actually something like 18.9998. It's close to 19,\nbut it's not quite there. Why do you think that would be? Well, the computer was trained\nto match only six pairs of numbers. It looks like a straight-line relationship\nbetween them, for those six, but it may not be a straight line\nfor values outside of those six. There's a very high probability\nthat it's a straight line, but we can't be certain. And this probability is built\ninto the prediction, so it's telling us a value very close \nto 19, instead of exactly 19. Try the code out using the link\nin the description below this video to see it for yourself. This is something you'll see\na lot more of in machine learning. And in the next video in this series,\nwe'll take what you've learned and apply that\nto a more interesting problem-- computer vision-- and seeing how you can\nteach a computer to see things, using exactly the same methodology\nas you used here. We'll see you in that video, and don't forget to hit\nthat subscribe button. Thank you! ♪ (music) ♪"
    },
    {
        "video_id": "6mSx_KJxcHI",
        "title": "Introduction to Machine Learning for Beginners [Part 1] | Machine Learning for Beginners",
        "url": "https://www.youtube.com/watch?v=6mSx_KJxcHI",
        "duration": 202,
        "transcript": "hello and welcome to this course on classical machine learning for beginners whether you're completely new to the topic or an experienced ml practitioner looking to brush up on an area we're happy to have you join us this course is based on the free open source 26 lesson ml for beginners curriculum from Microsoft which can be found at AKA dot Ms slash ml-beginners machine learning is one of the most popular Technologies these days I'm sure you've heard this term if you have any sort of familiarity with technology no matter what domain you work in however the mechanics of machine learning are a mystery to most people and the subject can sometimes feel overwhelming in this course you'll start right from the beginning and you'll learn about it step by step to practical Hands-On coding examples let's start by talking about the difference between artificial intelligence and machine learning AI is a science of getting machines to accomplish tasks that typically require human level intelligence many different techniques have been proposed for AI but the most successful and popular approach these days is machine learning unlike other AI techniques ml uses specialized algorithms to make decisions by learning from data so machine learning is really a subset of artificial intelligence you've also probably heard of deep learning which is a subset of machine learning that relies on neural networks to learn from data in this course we're going to cover what we call classical machine learning you'll learn some Core Concepts of ml a bit of History statistical techniques like regression classification clustering and more the concepts you'll learn here will serve you well as you progress to more Advanced Techniques keep in mind that this course won't cover data science deep learning neural networks and AI techniques other than ml Microsoft offers two additional courses for you to learn more about these areas data science for beginners available at AKA dot Ms slash data science beginners and AI for beginners available at aka.ms Ai and beginners machine learning is a Hot Topic because it's solving complex real-world problems in so many areas Finance earth science space exploration cognitive science and many more Fields have adopted machine learning to solve problems specific to their domains for example you can use machine learning to predict the likelihood of disease from a patient's medical history to anticipate weather events to understand the sentiment of a text and to detect fake news and stop the spread of propaganda applications of machine learning are almost everywhere and are as ubiquitous as the data that is Flowing from our devices and systems because of how useful it is understanding the basics of machine learning is going to help you no matter what domain you're coming from in the next video in the series I'll give an overview of the history of ml I'll see you there"
    },
    {
        "video_id": "jfSuQCs3bSs",
        "title": "Types of Machine Learning Algorithms Supervised Unsupervised Reinforcement Learning by Mahesh Huddar",
        "url": "https://www.youtube.com/watch?v=jfSuQCs3bSs",
        "duration": 659,
        "transcript": "welcome back in this video I will discuss what is the definition of machine learning and what are the different type of machine learning algorithm exists now the first question comes in front of us what is machine learning the definition of machine learning given by Tom Mitchell is one of the famous definition which was given in 1998 according to Tom Mitchell machine learning is the study of algorithm that improves the performance of P add some task t with experience e that is nothing but for a particular task if you design an algorithm if the performance of that particular algorithm is improving with experience then you can say that the machine is learning otherwise the machine is not learning so initially when you provide some set of experience for a given task the performance may be I can say that X and as and when you go on giving more and more experience to that particular algorithm the performance will go on improving from X to X Plus 1 X plus 2 and so on if it goes on improving then you can say that the machine is learning otherwise machine is not learning so this is one of the famous definition given by Tom Mitchell now we will try to see what are the different type of machine learning algorithms present there are three type of machine learning algorithms we have the first one is supervisor machine learning algorithm unsupervised machine learning algorithm and reinforcement machine learning algorithm we will see one by one in detail the first one is supervisor machine learning algorithms in supervised machine learning algorithm an artificial intelligence system is presented or given with a data which is labeled that is nothing but each and every example is labeled the correct value for example the first example may be given the value is second one may be given again yes third one may be given no and so on each and every example is given a correct label that data will be given as an input to the AI system in this case take an example to understand this particular part clearly let us say that we have collected some set of emails and uh along with that particular email what we do is we will assign some label to each and every email for example a email is spam email is not spam so you have email that along with that particular email we have assigned a label also so such data is called as the label data and this label data is given as an input to the supervised machine learning model for the purpose of training so as and when you go on giving this particular data to your model the model Will Go On Learning then when when the training is over you can test that particular model with the help of new emails uh the new emails will be classified into either spam or not spam based on the result you can check the accuracy of the model in this case this can be shown uh diagrammatically something like this we have to give some set of emails along with emails we have to give the labels also for example email is not spam here this email is Spam this will be given as an input to The Learning System it will go on learning as and when we go on providing some set of emails once it learns the model is created now what we do is we will give new emails with no labels then the Learned model will classify these new emails into spam or a not spam in this case I'll take one more example in this case uh this is the model uh what we want to train here to this particular model we are trying to give two things one is Apple and one more is orange here along with this particular thing we are trying to give the label also so again this is called as a label data once it it is gets trained we can give a new data and the new data will be classified based on the trained model in this case this is the overall picture of how the supervised machine learning model looks like the initially if we have some set of data the data will be divided into two parts the first part is uh the training data another one is the testing data the training data uh it may be anything for example it may be document image sound based on the kind of problem you are solving you may be having some set of data here along with this particular data we will give label to this particular machine learning algorithm what machine learning algorithm will do is it will take this input as well as label it will learn from that particular data you will get a predictive model here now once the predictive model is available you can give the new data but in this case you should not give the labels here the predictive model will take that particular new data and then it will give you the result here whatever the result you will get you can compare that particular thing with what you are expecting if everything is fine the meaning is the model has classified it correctly if the model has classified more number of examples correctly the meaning is it has learned otherwise it has not learned in that case now we will go to something called as uh uh what are the different type of supervised machine learning algorithms are there basically there are two types of supervised learning algorithms the first one is a classification in this case the target label or the can say that the label is either a categorical type for example red or blue this is or no disease and so on it may be two classes or it may be more than two classes also but it is if it is of type categorical type then it is called as a classification in this case if the problem what you're solving if it has the output variable or the target of of real value then it is called as a regression kind of problem uh or you can say that regression uh algorithm in that case so here uh some examples are like the target is the dollar value the dollar value is not a categorical it is a continuous value maybe 70 75 80 or something like that the weight is the another example if the target is of type weight weight is not a categorical value here you will get a continuous weights in this case also that's the reason it is called as a regression kind of problems over here now coming back to the unsupervised learning in unsupervised learning the artificial system is given uh unlabeled data or you can say that uncategorized data the data does not have any label in this case take an example we have given some characters to our model the characters may be ducks or not ducks but we we give this particular data without any label to that particular model what model will do it will take the hidden patterns of that particular data Maybe the similarity index or the distance between two data points and so on it will divide that particular data into multiple number of groups maybe clusters or you can say that some patterns will be generated and so on so that is what actually happens in unsupervised machine learning model so here this is what actually the data that's a ducks and nodex but we don't give any label to this particular thing unsupervised machine learning model will take this as a input it will check the hidden patterns because similarity index distance between the data points and then it will classify them into our group them into different clusters over here take an example of uh one more example here in this case we have given apple and orange as an input to this particular model but in this case we are not assigning or you are not given any label here so that's the reason it is called as unsupervised learning this is the overall picture of unsupervised learning here again we have the data based on our problem definition but the difference between this sentence supervised machine learning technique is we are not giving any label to the model here we are just giving the data based on that model is generated and then we have to give the new data to this particular model model will generate the likelihood classification clusters or better representations that's what actually happens in unsupervised learning coming back to the different types of unsupervised learning uh there they they may be classified into either clustering algorithms or Association rules over here clustering is like identifying the diff dividing the data into different uh groups that is what is called as clustering uh based on the customer's processing history they may be put into some different clusters that's what is the one example here Association is like uh you can say that Market Basket analysis also there is a possibility that if a particular person has bought X product he may tend to buy another product why so what we need to do is we need to put X and Y into one group so that's another type of unsupervised learning in this case the last type of algorithms are reinforcement learning algorithms in this case the agent learns by interacting with its environment that is whenever in environment the agent will perform some set of actions uh he may perform correct actions or he may not perform correct actions if you perform correct actions he will be given some rewards if he performs some incorrect actions he will be given a penalty so what happens over here is the agent will go on performing some different set of actions for a particular set of actions if we get a maximum reward that actions will be considered as the Learned parameters in this case so he will go on doing lot of actions for each and every action the record will be maintained like whether he has received the record reward or whether he has received the penalty and so on for a particular set of actions if he has received the maximum reward that will be the answer in this particular case take an example in this case uh the agent has two parts it has he has to go towards this particular actually the the tab but uh opposite to this one there is a fire also if you go towards this particular tab he will be given a reward if he goes towards this particular uh the fire he will be given a penalty in this particular case so he has to perform the actions and as and when he performs actions these rewards and penalties will be recorded the for a set of actions where he has got maximum reward that will be considered as a learned parameters in this case so this is about the reinforcement learning in this video I have discussed what is the machine learning what are the different type of machine learning exists I hope the concept is clear if you like the video do like and share with your friends press the Subscribe button for more videos press the Bell icon for regular updates thank you for watching"
    },
    {
        "video_id": "Drw2SA3mAls",
        "title": "Machine Learning algorithms: Supervised, Unsupervised and Reinforcement Learning",
        "url": "https://www.youtube.com/watch?v=Drw2SA3mAls",
        "duration": 197,
        "transcript": "[Music] my name is ron klostermann and i'm a product strategy manager for oracle machine learning algorithms fall into roughly three categories and i think it's important that you have a grasp of this first of all there's supervised learning what makes this unique is that here we have labeled historical data labeled means that our example data also holds the value of the thing that we try to predict so for example ask yourself now in the example for predicting house prices is that a supervised learning problem and yes of course it is because we have the house prices of that historical data so we can train a model on a known correct target value you'll hear people talk about regression and classification in regression we're predicting a continuous number a value so indeed our house price prediction is an example of that on the other hand sometimes we want to predict a class or a category for example we want to predict whether a customer will churn yes or no this is an example of classification so in the case of classification we are also creating a function but in this case the function will find the borderline between the classes and the line that best separates the different classes from each other now you'll gain some experience on classification in the lab on in database machine learning unsupervised learning is different because there we don't have a label we don't have desired expected output data so we cannot follow a training approach as we did with supervised learning instead what we do is just give the algorithm a set of input data and we basically ask it to find the hidden patterns in this data the most common example of this is clustering for example take a list of customers and separate them into two groups in this case it's up to the algorithm to find which customers are most alike looking at all of their attributes you can also use this technique to find anomalies in data for example for that fraud detection that i mentioned earlier reinforcement learning is entirely different here think for example about how you would teach a docker trick with a dog you would basically wait until it does something that's similar to what you want and then you give it a reward and the idea is that over time the dog will adapt its neural network or its function to reach the goal that you want we can use this same mechanism to teach a robot for example to pick up something on a factory line initially this robot will have a model that lets it move rather randomly but if it happens to get a bit closer to the goal that we've set it will get a kind of reward by the system and when that happens the machine learning model of the robot will change its weights and in the end we will have a robot that reaches its goal without us having to tell it how to do that [Music]"
    },
    {
        "video_id": "akhNqDtX_OI",
        "title": "Complete machine learning in 6 hours krish naik",
        "url": "https://www.youtube.com/watch?v=akhNqDtX_OI",
        "duration": 852,
        "transcript": "download this code from codeg.com link in the description below okay let's embark on a condensed yet comprehensive journey through machine learning in approximately 6 hours following the style and scope of Krishna Yak's tutorials this will be a fast-paced tour so be prepared to actively code along we'll focus on essential concepts and practical implementations disclaimer asterisk 6 hours is not enough to become a master of machine learning this tutorial aims to provide a solid foundation and a taste of various techniques to get you started further exploration and practice are crucial for deeper understanding prerequisites asterisk asterisk basic Python programming asterisk familiarity with data structures functions and control flow is essential asterisk environment setup asterisk install Anaconda Python distribution with pre-installed packages or minion create a virtual environment recommended to manage dependencies install the necessary packages pip install All numpy pandas psychit learn mattplot lilip seabourn outline 6-hour plan one introduction to machine learning 30 minutes asterisk what is machine learning asterisk types of machine learning supervised unsupervised reinforcement learning asterisk workflow of a machine learning project two data prep-processing 1 hour aster Asterisk data exploration and analysis using pandas asterisk handling missing values asterisk feature scaling standardization and normalization asterisk encoding categorical variables one hot encoding label encoding three supervised learning regression 1 hour 30 minutes asterisk linear regression asterisk polomial regression asterisk evaluation metrics for regression MSE RMSSE R 2 asterisk regularization L1 and L2 asterisk case study house price prediction for supervised learning classification 1 hour 30 minutes asterisk logistic regression asterisk k nearest neighbors KNN asterisk support vector machines SVM asterisk decision trees and random forests asterisk evaluation metrics for classification accuracy precision recall F1 score rock AU asterisk case study credit card fraud detection five unsupervised learning clustering 45 minutes asterisk K means clustering asterisk hierarchical clustering asterisk case study customer segmentation six model selection and hyperparameter tuning 45 minutes asterisk cross validation asterisk grid search and randomized search seven conclusion and next steps 15 minutes let's dive in one introduction to machine learning 30 minutes asterisk what is machine learning machine learning is a field of computer science that enables systems to learn from data without being explicitly programmed instead of writing explicit rules algorithms learn patterns and make predictions asterisk types of machine learning asterisk asterisk supervised learning asterisk training data is labeled input features and corresponding target values examples regression predicting continuous values and classification predicting categories asterisk unsupervised learning asterisk training data is unlabeled algorithms discover hidden patterns examples clustering grouping similar data points and dimensionality reduction asterisk reinforcement learning asterisk an agent learns to make decisions in an environment to maximize a reward asterisk workflow of a machine learning project asterisk one data collection asterisk gather data from various sources two data prep-processing asterisk clean transform and prepare the data three feature engineering asterisk select create or transform features to improve model performance four model selection asterisk choose an appropriate machine learning algorithm five training asterisk train the model using the prepared data six evaluation asterisk evaluate the model's performance on a test set seven hyperparameter tuning asterisk optimize the model's parameters eight deployment asterisk deploy the model for real world use nine monitoring asterisk continuously monitor the model's performance and retrain if necessary two data prep-processing 1 hour explanation asterisk asterisk loading data asterisk loads data using pandas readad csv asterisk exploration asterisk uses head info describe value underscore counts and visualizations to understand the data asterisk missing values asterisk identifies missing values with isnull dot sum imputes missing values using fila mean median mode or a constant value alternatively drops columns with too many missing values asterisk encoding categorical variables asterisk converts categorical features into numerical format using PD get underscore dummies one hot encoding or label encoder label encoding drop underscore first equals true in one hot encoding avoids multiolinearity asterisk feature scaling asterisk scales numerical features using standard scaler standardizes data to have zero mean and unit variance other scalers include minmax scaler three supervised learning regression 1 hour 30 minutes explanation asterisk asterisk data preparation asterisk splits data into training and testing sets using train test_split defines features x and target variable y asterisk linear regression asterisk creates a linear regression model trains it on the training data makes predictions on the test data and evaluates the performance using MSE and R squar asterisk polomial regression asterisk creates polomial features using polomial features transforms the data trains a linear regression model on the transformed data and evaluates the performance asterisk regularization asterisk demonstrates ridge L2 and lasso L1 regression to prevent overfitting alpha controls the regularization strength asterisk evaluation metrics asterisk MSE mean squared error measures the average squared difference between predicted and actual values r 2 represents the proportion of variance explained by the model lower MSE and higher R squar are generally better four supervised learning classification 1 hour 30 minutes explanation asterisk asterisk classification models asterisk implements logistic regression KN&N SVM decision trees and random forests asterisk evaluation metrics asterisk asterisk accuracy asterisk overall correct predictions asterisk precision asterisk correct positive predictions out of all predicted positives asterisk recall asterisk correct positive predictions out of all actual positives asterisk F1 score asterisk harmonic mean of precision and recall asterisk rock asterisk area under the receiver operation Rating characteristic curve measures the model's ability to distinguish between classes asterisk rock curve asterisk plots the true positive rate TPR against the false positive rate FPR for different classification thresholds helps visualize the tradeoff between sensitivity and specificity five unsupervised learning clustering 45 minutes explanation asterisk asterisk k means clustering asterisk groups data points into clusters based on their distance to cluster centroidids n_clusters specifies the number of clusters asterisk hierarchical clustering asterisk builds a hierarchy of clusters elomemerative clustering starts with each data point as a separate cluster and merges them iteratively asterisk silhouette score asterisk measures the quality of clustering values close to one indicate good clustering while values close to minus one indicate poor clustering asterisk data scaling asterisk scaling data is essential before using distance-based models like KNN and K means here minmax scaler is used to scale data to range between zero and one six model selection and hyperparameter tuning 45 minutes explanation asterisk asterisk cross validation asterisk splits the data into multiple folds and trains and evaluates the model on different combinations of folds provides a more robust estimate of model performance asterisk grid search asterisk exhaustively searches a predefined grid of hyperparameter values to find the best combination asterisk randomized search asterisk randomly samples hyperparameter values from specified distributions can be more efficient than grid search for highdimensional hyperparameter spaces seven conclusion and next steps 15 minutes asterisk recap asterisk we've covered the essential steps in a machine learning project including data prep-processing regression classification clustering model selection and hyperparameter tuning asterisk next steps asterisk asterisk practice asterisk work on more data sets and projects to solidify your understanding asterisk deep learning asterisk explore neural networks and deep learning frameworks like TensorFlow and PyTorch asterisk advanced techniques asterisk learn about more advanced topics like ensemble methods dimensionality reduction and feature engineering asterisk stay updated asterisk machine learning is a rapidly evolving field stay updated with new algorithms techniques and tools asterisk real world projects asterisk apply your knowledge to solve real world problems contribute to open-source projects Important considerations and tips asterisk asterisk data quality is key asterisk the performance of your models depends heavily on the quality of your data spend time cleaning and pre-processing your data asterisk feature engineering asterisk carefully selecting and creating features can significantly ly improve model accuracy asterisk understand your data asterisk thoroughly explore and analyze your data to gain insights and identify potential issues asterisk overfitting asterisk be aware of overfitting where your model performs well on the training data but poorly on unseen data use techniques like regularization and cross validation to mitigate overfitting asterisk choose the right algorithm asterisk select the appropriate algorithm based on the type of problem you are trying to solve and the characteristics of your data asterisk experiment and iterate asterisk machine learning is an iterative process experiment with different algorithms hyperparameter settings and feature engineering techniques to find the best solution don't be afraid to ask for help the ML community is very helpful don't hesitate to post on Stack Overflow Reddit etc this tutorial provides a starting point for your machine learning journey good luck and have fun exploring the world of machine learning remember to practice experiment and continue learning"
    },
    {
        "video_id": "CiSaY2xl9V4",
        "title": "Ten Everyday Machine Learning Use Cases",
        "url": "https://www.youtube.com/watch?v=CiSaY2xl9V4",
        "duration": 427,
        "transcript": "everybody is talking about generative AI but gen AI is a subset of the larger field of machine learning and I'm going to give you 10 use cases of how machine learning or ml is used today in everyday life and by Machine learning I'm talking about these sub field of artificial intelligence in which machines learn from data sets and past experiences by recognizing patterns and generating predictions now now machine learning is projected to become a $200 billion industry by 2029 but it's already very much here today so let's get into it now one aspect of machine learning that's seen huge utility is NLP or natural language processing that's the ability for machines to make sense of the unstructured mess that we like to call human language so use case number one is customer service text based queries can be handled by chatbots which act as virtual agents that many businesses provide on their e-commerce sites the chatbots can resolve many queries themselves and where they can't they can routes customers to where they can find the appropriate help from a human customer service representative ml also Powers voice assistance things like Siri and Alexa where first speech to text and then NLP machine learning models help understand a spoken command that same capability is used by services like slack and YouTube to power Auto transcription of spoken words in video content now number three is ML and mobile apps where would we be without spotify's ml models for generating song recommendations or linkedin's use of ml to make employment suggestions your phone is likely filled with apps that call out to Services running machine learning models and actually ml in smartphones really deserves its own category because with the power of modern smartphones some of that machine learning is performed directly on the device such as computational photography to generate background blur and your selfie shots or unlocking your phone with facial recognition or onboard device image classification models that help you to search your photo library like that time I was trying to find this picture of my cat where he jumped into the dryer ml helped me to find that without me spending a ton of time scrolling through my photos app hey the dry wasn't actually on now now that's an example of a needle in a hyack problem thousands of images and there's only one I'm looking for which in a way is is similar to use case number five that is financial transactions now in the us alone there are 150 million credit card transactions every day and the vast majority of those are legitimate how to detect the fraudulent ones well ML and deep learning are widely used in fraud detection where financial institutions train ml models and classification algorithms to rec ize suspicious online transactions and flag them for further investigation 150 million credit card transactions every day is 1,739 every second so this is a task that would be near impossible to perform manually well did you also know that between 60 and 73% of all Stock Market trading is conducted by ml algorithms and that percentage is increasing every year all right let's quickly knock out a couple more so ml is used frequently in cyber security reinforcement learning uses ml to train models to identify and respond to cyber attacks and detect intrusions ml informs a lot of our transportation these days for instance Google Maps uses ml algorithms to check current traffic conditions and determine the fastest route and right sharing apps like uber and lift use ml to match Riders to the drivers and ml plays a large role in filtering email messages as well through classification of incoming messages and autocomplete responses now number nine that's Health Care this is one example where machine learning can help augment and speed up human capabilities now it's estimated that doctors evaluating mammograms Miss between 30 to 40% of cancers and the rate of false positives is even higher ml is already helping here where pattern recognition models are trained to classify tumors that are hard to see with a human eye this is increasing not only the accuracy of interpreting Radiology Imaging but it's also increasing the reading time of Radiologists allowing them to focus their attention on the more suspicious examinations flagged by the ml models there are also ml successes in early lung cancer screening and finding bone fractures okay one last one and and a question for you in general which department in an organization uses Ai and machine learning the most well according to Forbes it is the marketing and sales department marketers use ml for lead generation data analytics and search engine optimization and they often build on top of existing ml models so for example consider how recommendation algorithms like those at net nflix make TV and movie suggestions as to what to watch next based on your derived tastes and interests well the marketing and sales department can use those same ml models for targeted personalized marketing campaigns tailored to those very same tastes and interests look we we hear so much these days about the future of AI and in particular a GI artificial general intelligence that will one day match and surpass the intelligence of humans but but right now that level of AI doesn't exist it's theoretical but machine learning that's AI that is already here and it really is very much part of our everyday lives if you have any questions please drop us a line below and if you want to see more videos like this in the future please like And subscribe thanks for watching"
    },
    {
        "video_id": "67dBA4xYxNU",
        "title": "Top 10 Applications of Machine Learning | ML Applications and Examples  | Machine Learning",
        "url": "https://www.youtube.com/watch?v=67dBA4xYxNU",
        "duration": 557,
        "transcript": "hello everyone my name is anit VMA and today we are learning the applications of machine learning the first application is virtual personal assistant say example we are having the Alexa Cortana hey Siri hello Google these are the virtual personal assistant virtual means there is a computer which is virtually present personal means they are helping us personally as a assistant means whatever we are asking the computer they are solving our query so they use the NLP NLP is natural language processing so there is a intelligent agent present in the form of computer and they are understanding our natural language means whatever we are speaking they are understanding and based upon that they are recognizing our speech and they are doing such action just like playing the song or giving us the direction and so many other tasks so these are the virtual personal assistant next application is traffic prediction means predicting the traffic today we are having the Google Map and through the Google Map we can easily find which is the best route for going from one location to another they are also telling us that wherever we are having the congestion or which path is free so easily we can predict the traffic the next application is email spam filtering the meaning is that in the email we are going to filter those males which are spam we can see that in our Yahoo or Gmail we are having the option of spam so here all those mails which are not useful for us or which are fishy these mails are automatically sent to the spam so there all the spam mails are collected this is the application of machine learning next application is online fraud detection through the machine learning we and detect the online fraud today there are various fraudrin people who are going to steal our details of ATM card debit card by which they are performing the operation and they deduct the money from our bank account so these are the fraud and in this online fraud this can be detected by the machine learning next is is Stock Market trading with the machine learning we can easily check where the market is growing what is the upcoming prediction where we should invest our funds so with the help of machine learning we can do the Stock Market trading the next application is automatic language translation one language can be converted to other language automatically this is called automatic language translation let us suppose that somebody is speaking in English and from the device on the other side we are having the language converted to the Japanese so here English and Japanese these two person can communicate very easily and this is done automatically by the machine learning application the next application is recommendation engine the meaning is that we are recommending something today the Netflix YouTube Amazon Prime and so many other OT platforms are recommending their movies and based upon that their videos and movies are promoted and people are watching that this is the recommended system similarly Amazon flip cart mintra are recommending their products using the product recommendation and based upon that there are so many people who are purchasing their product this is all possible because of the machine learning next is self-driving car the drivers are not required in the self-driving car because they can drive byself there are so many sensors which are placed these sensor can judge the distance from the other car and they can also judge the road traffic and based upon the machine learning algorithm they can decide where they should move and at which speed so these cars are self-driven next application is medical diagnosis we can easily predict the problem with the patient using the machine learning algorithm here we can predict what are the probable cause for the problem and we can treat the patient very easily the next application is image recognition today with the machine learning we can recognize the face very easily we can also match the photo with the sketch let us suppose that we are having a sketch of a criminal we can match with the database using the image recognition so all these are possible because of machine learning next application is speech recognition our mobile tablets they can recognize our speech means whatever we are saying they are doing certain operation just like if we are saying to call somebody they are doing the call so this is the speech recognition which is possible because of NLP which is natural language processing they process the human voice and take the decision accordingly next application of machine learning is chatbot chatbot meaning is chat is chatting bot means it is a computer generated bot so bot is doing the chat today in the modern websites in the corner we are having a chat bot which helps in solving our query if we have some query we can type and these chat bot can answer so based upon our question they give us the answer this is only possible because of the machine learning next application is virtual Tryon the meaning is that virtually we can try something let us suppose that we want to purchase the specs then virtually on our face we can place the specs and we can check which specs is looking good or let us suppose that we want to purchase some jeans we can virtually try it so these are the virtual Trion so using the machine learning we can virtually try the things which we want next application is social media personalization using the machine learning sentiment analysis is done the meaning is that here we are checking the customer Choice the customer is happy or not means customer want which thing so we should produce the same thing that is the sentiment analysis means analyzing the sentiment of customer and based upon that those things which are liked by the customer they are promoted on the Instagram Facebook Twitter LinkedIn so that their social media can be personalized and they can enjoy all the things which they want next application is gamified learning nowadays there are various apps available through which kids can play the game and they can learn about their Concepts so this is the gamified learning means learn from the games so these are the all applications of machine learning that's all for today thank you"
    },
    {
        "video_id": "me3QEYPsFWE",
        "title": "APPLICATIONS OF MACHINE LEARNING THAT WILL BLOW YOUR MIND",
        "url": "https://www.youtube.com/watch?v=me3QEYPsFWE",
        "duration": 325,
        "transcript": "ten machine learning use cases machine learning is powered by insights the pace and quality of algorithms improvements rely not as much on computing power or impeccable code as rather on high quality data if the company knows how to collect information from its users monitor on-site interactions and listen to social media posts they can achieve remarkable results as shown by Google Amazon Netflix Microsoft Facebook let's take a look at machine learning applications in multiple industries to see how this technology can be applied to real-life problems one image recognition the neural network takes a ready library of images and analyzes them pixel by pixel to detect objects and features on images each neuron offers insight after validating their piece of contents and the network unites millions of these conclusions into a cohesive analysis the great example is clear view a facial recognition technology that analyzes data from social media to get insights on people's faces and get their data to social media analysis machine learning can analyze millions of posts on Facebook Twitter Instagram read comments and personal updates machine learning allows systems not only to recognize words but understand the context behind them just imagine what if a machine learning system analyzed your Facebook feed which conclusions with the system make share your guesses in the comments now it can help businesses keep up with customer feedback track their brand health and improve reputation the lion bridge project is a great example this sentiment analysis tool provides users with insights based on social media posts in more than 300 languages 3 smart assistants with machine learning smart assistants can analyze personal data process voice requests automate daily tasks and adapt to changing user needs Alexa by Amazon or instance use all collected data to improve its pattern recognition skills and be able to address new needs for news classification as the amount of produce content grows exponentially businesses and individual users need tools that would classify and sort out the information the algorithms can run through millions of articles in many languages and select the ones that are relevant to user interests and habits 5 video surveillance machine learning can help develop complex algorithms for video recognition at first using human supervision the system will learn to spot human figures unknown cars and other suspicious objects soon it'll be possible to imagine a video surveillance system that functions entirely without human supervision 6 optimization of search engine results machine learning algorithms can use user habits and interests from analyzing search statistics the rating algorithms won't rely on meta tags and keywords but instead will analyze the context of the page google ranked brain is a great example of this idea 7 email analysis machine learning techniques can analyze and compare legitimate emails with spam and determine differences even in cases where humans would easily make a mistake 8 speech recognition machine learning helps the software to adapt to dynamic speech patterns users use idioms slang abbreviations and to stay flexible a system needs to learn all these altered versions this is where machine learning is essential even theoretically a human team can't teach millions of speech variations to the software manually if the system trains itself however the task becomes much more manageable 9 cyber security machine learning algorithms can immediately detect cyber security threats the system will recognize the threat analyzed similar cases and take measures to secure the website or application it allows businesses to be up to date with malicious practices and predict safety issues before they even come up 10 customer service machine learning algorithms analyze customer behavior from this data chat bot developers can know which issues to focus on as soon as several dozens of responses were confirmed the chat BOTS can learn on their own from daily interactions with clients getting better with each dialog machine learning is a long-term investment that delivers continuous improvements as your business grows the software equipped with ml algorithms will become better with every next client interaction analyzed database or text file the more it works the more precise its insights become which is a perfect success formula for scalable businesses the gelwix team has great experience of developing machine learning and AI projects need experts help find our contact details in the description box and don't hesitate to reach out thank you for watching don't forget to like this video and subscribe to our Channel [Music]"
    },
    {
        "video_id": "EuBBz3bI-aA",
        "title": "Machine Learning Fundamentals: Bias and Variance",
        "url": "https://www.youtube.com/watch?v=EuBBz3bI-aA",
        "duration": 396,
        "transcript": "Hurricane Florence came by while I was working on stat quest dark clouds filled the sky but that didn't stop stat quest stand quest hello I'm Josh stormer and welcome to stat quest today we're going to be talking about some machine learning fundamentals bias and variance and they're gonna be clearly explained imagine we measured the weight and height of a bunch of mice and plotted the data on a graph light mice tend to be short and heavier mice tend to be taller but after a certain weight mice don't get any taller just more obese given this data we would like to predict Mouse height given its weight for example if you told me your mouse weighed this much then we might predict that the mouse is this tall ideally we would know the exact mathematical formula that describes the relationship between weight and height but in this case we don't know the formula so we're going to use two machine learning methods to approximate this relationship however I'll leave the true relationship curve in the figure for reference the first thing we do is split the data into two sets one for training the machine learning algorithms and one for testing them the blue dots are the training set and the green dots are the testing set here's just the training set the first machine learning algorithm that we will use is linear regression aka least squares linear regression it's a straight line to the training set note the straight line doesn't have the flexibility to accurately replicate the arc in the true relationship no matter how we try to fit the line it will never curve thus the straight line will never capture the true relationship between weight and height no matter how well we fit it to the training set the inability for a machine learning method like linear regression to capture the true relationship is called bias because the straight line can't be curved like the true relationship it has a relatively large amount of bias another machine learning method might fit a squiggly line to the training set the squiggly line is super flexible and hugs the training set along the arc of the true relationship because the squiggly line can handle the arc in the true relationship between weight and height it has very little bias we can compare how well the straight line and the squiggly line fit the training set by calculating their sums of squares in other words we measure the distances from the fit lines to the data square them and add them up just they are squared so that negative distances do not cancel out positive distances notice how the squiggly line fits the data so well that the distances between the line and the data are all 0 in the contest to see whether the straight line fits the training set better than the squiggly line the squiggly line wins but remember so far we've only calculated the sums of squares for the training set we also have a testing set now let's calculate the sums of squares for the testing set in the contest to see whether the straight line fits the testing set better than the squiggly line the straight line wins even though the squiggly line did a great job fitting the training set it did a terrible job fitting the testing set in machine learning lingo the difference in fits between data sets is called variance the squiggly line has low bias since it is flexible and can adapt to the curve in the relationship between weight and height but the squiggly line has high variability because it results in vastly different sums of squares for different data sets in other words it's hard to predict how well the squiggly line will perform with future data sets it might do well sometimes and other times it might do terribly in contrast the straight line has relatively high bias since it cannot capture the curve in the relationship between weight and height but the straight line has relatively low variance because the sums of squares are very similar for different data sets in other words the straight line might only give good predictions and not great predictions but they will be consistently good predictions BAM Oh No terminology alert because the squiggly line fits the training set really well but not the testing set we say that the squiggly line is over fit in machine learning the ideal algorithm has low bias and can accurately model the true relationship and it has low variability by producing consistent predictions across different data sets this is done by finding the sweet spot between a simple model and a complex model oh no another terminology alert 3 commonly used methods for finding the sweet spot between simple and complicated models our regularization boosting and bagging the stat quest on a random forest show an example of bagging in action and we'll talk about regularization and boosting in future stat quests double bam hooray we've made it to the end of another exciting stat quest if you liked this stack quest and want to see more please subscribe and if you want to support stack quest well please consider buying one or two of my original songs alright until next time quest arm"
    },
    {
        "video_id": "BqzgUnrNhFM",
        "title": "Machine Learning-Bias And Variance In Depth Intuition| Overfitting Underfitting",
        "url": "https://www.youtube.com/watch?v=BqzgUnrNhFM",
        "duration": 1013,
        "transcript": "[Music] hello on my name is Krishna and welcome to my youtube channel so guys today in this particular video we are going to discuss a very important topic which is called as bias and variance and then we are also going to discuss about topics like overfitting under fitting I probably think you have heard a lot and if I talk about just bias and variance you also heard about terminologies like high bias low variance low bias high variance like all this kind of terminologies will try to understand properly and we are going to take both the example of regression and classification problem statement and will understand these terms so let us take an example over here I have a problem statement with respect to x and y these are my points and our aim is actually to create a best fit line with the help of a linear regression and there are various different kind of linear regression like multiple linear regression polynomial linear regression here specifically I've used polynomial linear regression now when my degree of polynomial is equal to one that basically means this polynomial linear regression will just be acting like a simple linear regression so it will try to create a best fit line now based on this actual points and you know that guy's linear regression is a problem I mean it is a model which is actually just create a best fit line it is not suitable for you know the nonlinear separated points or nonlinear spread points right so over here my point is actually spread in this particular shape right it is in the shape of a curve but if I have degree of polynomial is equal to 1 I just get a best fit line now when I compute the R squared error definitely the a squared error will be high you know it will be on the higher side because again you understand this is my predicted point this is my actual point that if I do the summation of all the errors right it will be usually high right now suppose if I increase the degree of polynomial is equal to 2 in the polynomial linear regression what will happen is that now the best fit for line will actually become a little bit smaller curve right it will be a little bit smaller curve now in this scenario you can see that it is actually satisfying most of the training points and definitely the error is very very less right the error is very very less now let us go one more step ahead the degree of polynomial is equal to four now you can see that this is a condition where each and every point is exactly fitted to this particular curve line now let us go back ahead to this particular thing only when my error is very very high and I understand is we had created a model on a training data set and for the training data set it is giving a very high error so this scenario we basically call it as under fitting right under fitting basically says that for whatever data have trained my model there is quite high for that right I'm just not talking about my test data or the new data this is just only with respect to the training data even for the training data my error is very very high so this is basically an under fitting condition now let us go back to the last diagram oh here I probably think youyou know about this now since each and every point is getting satisfied by this best fit line right now this is a scenario where I can say it has overfitting I'll tell you why we are saying it as overfitting now just to understand guys okay now overfitting basically means what now with respect to training data this particular best fit line satisfies all the points perfectly right but just understand if we have some new points suppose my test points are over here suppose my new test points are over here suppose it is here it is here it is here it is here right now just understand when this best fit line satisfied properly on the test data again the error rate will be high in overfitting condition even though for the training data the icarus is quite high but for the test data the kracie goes down okay so what what I'm saying for the training data for the training data I can write it as accuracy is very very high but for the test data the accuracy is very very it's going down in this scenario what is happening in this scenario what is happening in this scenario my accuracy of the training data Micra see of the training data accuracy is going down right for the test data also the accuracy is going down right right I hope you have understood this in this case the training data the crease is very high but for the test data the crease is very low why so what's over here for the training need also the crease is less and for the test data also accuracy is less so that scenario we call it as under fitting this scenario we call it as overfitting our main aim should be in such that for the training data also migration should be high and for the test data or for the new data also my accuracy should be high and that is actually solved by this particular degree of polynomial is equal to 2 now in this scenario out of these three models you know I should be selecting this model in order to solve my problem statement now this is the most suitable model that we should select and in this particular model you can understand guys this particular model is you can say it as this particular model is basically giving us lower bias low variance low bias and low variance now is this let's discuss about this what is bias and variance I have just told you about overfitting and underfitting but what about bias and variance now let's go over here in the under fitting scenario in the under fitting scenario I basically have I basically have high bias and high variance always remember this thing's guys or and underfitting I always have high bias and high variance bias basically means the error of the training data let's consider think in this particular way okay the error of the training data variance basically says that it is the error of the test data okay so we have high bias and high variance obviously for the training data the error is high for that test data error is high that is what is under fitting condition now let's go back to the overfitting in this scenario I will be saying that over here I have low bias and high variance why low bias understand for the training data that is less right when therefore the training data the error is less we basically denote it as bias since the error is less we call it as low bias but for the test data we are getting a huge error so we are calling it as high variance okay I hope you have understood so for this particular scenario will be having low bias and low variance because for the training data also we are getting less error for the test data also we are getting less setup pretty much simple I hope you have understood this I hope you have understood it much more perfectly if you have not just rewind it you guys just rewind the video and try to understand in this also for the new test data also I will be getting a high error for this also I will be getting a high error right when I compare this this will be giving us a low error okay this was with respect to the regression problem statement now let us go to the classification problem stain now classification problem statement suppose I've used three models with three hyper pure parameter tuning techniques have have done some hyper parameter optimization for the first time my model one my training error was 1% okay classification problem statement basically means and trying to compare whether my model is able to do a binary classification like yes or no and usually you know that we use a confusion matrix for that right so over here suppose my model one gives the training error of 1% my model to model 1 gives the test error of 20% I just understand what kind of scenario this is one person basically means low bias right test error is high so it will become high variance so in this scenario what is the scenario where low bias and high variance if we have low wise and high variance what is the scenario this scenario is basically called as overfitting this scenario is basically called as overfitting right now let us go to the second model in the second model my training error is 25% my test error is 26% now in this scenario what do you think should be you know training error is given 25% again understand this if your model is just 7 percent accurate I think you should try to improve that particular model yeah so it also depends on the domain that you are working but right now I'm considering that this is actually a under fitting problem what is under fitting problem high bias high variance since my training error is high I'll say it as high bias if my since my test error is very high I am going to say that's high variance okay now next three in this model three in model three what is happening my training error is less than 10% my test error is less than 10% now this is the scenario that we are covering over here which is nothing but low bias and low variance so this becomes an under fitting problem this becomes the most generalized model right so I hope you have understood these things now this is pretty much important to understand what I'm going to do guys I'm just going to rub this diagram okay and I'm going to show you a general representation of this bias and variance how it is shown in graphical order okay we will try to understand that okay guys let us go ahead and try to understand the general representation of bias and variance I'll take the same example what I have actually taken over here in my x-axis is degree of polynomial over here in the y axis it is error so understand if you have an under fitting condition what will happen usually the error rate will be high so error rate for the training data will also be high error rate for the test data will also be high right okay now let us go and try to understand this overfitting condition in the overfitting condition what will happen in the old fitting condition if I take this particular example over here or let me just okay understand guys this red point is basically my training error this blue point is basically my cross-validation error or you can also say it is test error okay so we'll just try to write in this particular way okay now for the overfitting condition you can you know that I have low bias and high variance so my training error for the training data I mean for the training data it will become less so suppose I am going to mention this particular point okay now with respect to this particular point you you can see that for the test data it is high variance so the error rate for the cross-validation error will be high in the case of overfitting problem statement right when my degree of the polynomial hi in this case my degree of polynomial is high so I am just going to keep this particular point like this let me combine this particular point like this okay so I have combined this particular training error like this it will go like this itself okay fine now about this particular point okay you will be able to see that you will be also able to see that this points will also reduce like this at certain point and then after that it will again increase okay now this particular point that I was talking about it is nothing but high variance for the same degree okay high variance for the same degree because I told you till till at certain point again your cross-validation error will be reducing but after certain point you know since you are overfitting the problem statement it the accuracy sorry the accuracy or the error rate the error rate will actually be increasing so our aim is to actually click find out a model you know where this generalized formation can come this generalized model can be created like based on the errors that we are getting over here and this scenario is nothing but low bias and lower variance now in up from this particular graph you can see that this particular point is actually having low bias and lower variance pretty much simple guys so I have hope you have understood this is the general representation of bias and variance let us go ahead and take some examples with respect to decision tree and random forests and then we'll try to understand whether it is an or fitting condition or under fitting condition now by default you know that guys decision tree creates disguised row of trees itself right completely to his depths it takes all the features and then it starts splitting to its complete depth okay now when it does this this scenario is just like an over fitting condition okay this scenario is just like an over fitting condition now in over fitting you just split all the decision tree till is complete that definitely for the training data this may give you a very good result okay the error rate will be less but for the test data guys this scenario not work now this scenario this decision tree basically has a scenario of you know low bias low bias and high variance it has a scenario of low bias and high variance because understand because we are just training on the data on the training data Excel and we are splitted it to is completely depth trained enough for the test data definitely this is not going to give you a very good result you know so because of this we use techniques like decision pruning we try to only create the decision tree up till some depth you know after that that will not still split so that is the way of actually converting this high variance into low variance and again there are a lot of hyper parametric techniques hyper parametric tuning techniques guys and definitely you should go and explore or about decision tree regarding that now let us go ahead and take an example of a random forest in random forests we use multiple decision tree in parallel okay multiple decision tree in parallel and when we consider random forest guys when we consider random forest since we are using multiple decision tree in parallel we basically have a scenario of something like low bias and since we are since we are using decision tree again I am Telling You initially it will have this kind of property of high very low bias and high variance this will be the property with respect to each and every decision tree but since we are combining those decision tree in parallel because understanding random Forsch what is there it is basically called as bootstrap aggregation bootstrap aggregation in bootstrap aggregation what we do we take a data set we give it to multiple models okay we give we give this data set we get we don't get the whole records but we give a partial sum n number of records to different different decision trees okay and finally we get the output and we can aggregate it we aggregate it and then we see that who suppose many models are actually given a value as one then we'll consider that output is one if many model gives us the output as 0 we'll consider the output as 0 now initially since I was using many decision trees and each and every decision tree has a property of low bias and high variance if I combine this in a path this high variance will get converted to low variance okay how it is getting converted to ha from high variance to low V in it since we are using this decision tree parallely and remember this is my data set this is my model M 1 M 2 M 3 M 4 not all the data set is going right there only some data set that will be going suppose 20 record goes over here 20 record goes over here 20 record goes over here 28 the card goes over here suppose in my data set the total number of records are 80 so it will be splitted in this particular manner and then it will be trained on that particular water and output will be given to us how you should understand that the high variance which was present in one single decision tree since we are combining all the decision tree in parallel it is getting converted into low variance so this was just one example with respect to decision tree and random forest one question is that what kind of technique xg-- boost have doesn't have high way high bias and low variance or does it have low bias or low variance you don't basically answer me that please do comment down in the comment box of this particular video but I hope you have got the idea of bias and medians guys I hope you know now what is underfitting what is overfitting you know I hope you know that if somebody says low bias and high variance that is an overfitting scenario or underfitting scenario you should know that ok so yes this was all about this particular video please do let me know like if you have any other questions and I'll see you all in the next video have a great day thank you one and all bye-bye"
    },
    {
        "video_id": "-avfmXMCXSo",
        "title": "3.2 Bias and Variance, Bias Variance Trade off",
        "url": "https://www.youtube.com/watch?v=-avfmXMCXSo",
        "duration": 230,
        "transcript": "hello guys we are back with our next lecture in this lecture let us go through the concept of bias and variance so if you recall we have already discussed about variance right so variance explains about the spread of data right yes and by answer it represents the gap in between the predicted values and original values got it yes okay so that's just some basic definitions you can say guys so i'll be explaining you the concept of variance and by also using these four uh charts list you can say okay so assume that this is the dart board right so we'll be having bullseye in the center so our goal is to hit the bullseye right so that is our goal right so if your variance is low what is the situation guys if your variance is low all your items will be close to each other right yes similarly if your bias is low you you are 100 accurate right so based on our val on our definitions right yes so that is the reason why all your values are already inside the bullseye okay yes similarly if your bias is of good like low okay so your values will be will not have that much graphic they will be closer but you are having high variance then the distance between these items are the points will be far right so that is the reason why they are in the second layer okay similarly if your bias is high means you are not predicting exact values in that situation your values will be somewhere else right and if your variance is low you they will be scattered at a single point right so i'm just giving you in terms of diagrams guys because i cannot explain these in words right yes similarly if your bias and variance both are high then your values will be too far from the bullseye so basically the ideal thing which we need is a low variance and a low bias guys got it yes so that's what i was trying to say okay yes so if you check the next topic that is nothing but bias variance trade-off so this thing says about this only guys okay got it yes so it it is also recommended to have low bias and low variance okay so if we have high bias it will under fit the model okay guys i'll be showing you an images for under fitting and overfitting don't worry so if we have high bias we are going to under fit the model and if we are having high variance we are going to over fit the weight bias okay so basically you will be having a doubt that what is this over fitting what is this balanced and what is this under fitting right yes so what is a balance this so let us come from over fitting us so overfitting is a state in which your graph or your line will try to connect to each and every point so if you notice here it is trying to connect each and every dot right yes so this concept is called as over fitting is okay similarly if your graph is in a proper structural way and it is touching some points it is not touching all the points or it is not missing all the points that is a good or robust graph guys when your graph is not touching any point like see here the point started from here to here and the line is going from here so that is not a good thing right yes so that is nothing but the under fitted graph okay i don't know exactly how you can write the definitions for them guys but with the diagrams it is really easy to explain so that is the reason why draw the diagram and explain your own words guys okay yes so i hope everyone got a clear idea about these three graphs so in the next lecture we will be continuing with the bears classification and insight based classification we'll be discussing about base theorem guys mostly i'll be connecting you back to a video which we have already done in the data mining guys okay so as i don't want to repeat the videos again and again okay in the next lecture we'll be discussing about bayer's optimal classifier okay yes so let us meet in the next lecture thank you thanks for watching you"
    }
]